\documentclass[9pt]{article}
\usepackage{ulem} 
\usepackage{soul} 
\usepackage{parskip}
\usepackage{array}

\setuldepth{2}
\setlength{\parindent}{0pt}

\title{A Standardised Benchmarking of Denoising Auto-Encoders in fNIRS Systems}
\author{ \large{ \ul{Konstantinos Agusti Demiris} }\vspace{0mm}\\\small {First Year Undergraduate Student} \\ \small {Physiological Computing and Intelligence Lab, UCL}\\ \small{UCL Undergraduate Research Program} \\\vspace{1mm} \footnotesize under the supervision of \\ \vspace{2mm} {\small \ul{Professor Youngjun Cho}} \vspace{-1mm}\\\footnotesize{and}\\ \vspace{-2mm} {\small \ul{Zikun Quan}} \vspace{5mm}}
\date{18 July, 2024}

\begin{document}
\maketitle
\pagebreak
\vspace{-4mm}
\underline{\textbf{Abstract:}}
\vspace{-2mm}

We investigate the application of Denoising Auto-Encoders in the removal of confounding physiological noise from fNIRS signals, which to the best of our understanding has not yet been covered in any previous study. 

Among five different common implementations from literature, and two newly proposed variations,

We achieve a ()\% improvement in SNR and a 92.8\% detection rate on readings  from unseen participants, with unknown activation periods, with no additional sensors or the use of short-separation channels.

This suggests the potential of further development and usage of these techniques in supporting the development of less intrusive, lighter and more discreet fNIRS systems, by mitigating the signal quality downsides.

We additionally provide an open-source toolkit for signal denoising, data generation and performance benchmarking, both for regular usage and as a foundation for further studies.

% Put the 'with the rise of' stuff to the intro, and write a very 'dry' abstract. It should be succinct and clear.
With the rise in research into the use of deep learning based techniques in fNIRS systems, we have found a gap in the literature regarding the preprocessing of fNIRS haemodynamic responce signals using deep learning, and as such we look into applying Auto-Encoders for the removal of confounding physiological noise from fNIRS signals. We test the performance of different variations of the Auto-Encoder Architectures, both from literature and new proposed forms, on three categories of fNIRS signals against several metrics. 

We evaluate their performance, discuss their potential as well as providing a toolkit for regular usage and as a foundation for further advancements. ----> MAKE MORE MEATY, explain what did i actually do rather than generalities. e.g. showing that a denoising controller performs x% better than current methods. Explain what the potential actually is in the abstract. Don't try to only explain the structure, just talk through the actual contributions. (e.g. talk through what the potential further uses actually are)

\ul{\textbf{keywords:} Auto-Encoder, fNIRS, denoising signals, deep learning, BCI, physiological computing}

\underline{\textbf{1. Introduction:}} 

\textbf{general notes: if the detail is necessary for info and understanding, or justifying why you did something, instead put a reference to it, and include it in the appendix, so that it doesn't break the flow of the information}

\textbf{I don't think I put anywhere, so i should if i haven't, but I am doing this on a per channel basis... and also the data that we are using is taken from a mix of multiple channels. Additionally mention that I am using impulse/instantaneous stimulus hrf, but if you want to consider longer stimuli or activation periods, it's a potential direction of further development, as is the overlaying of multiple hrfs over one another}

\ul{1.1. Functional Near Infrared Spectroscopy}


Functional Near Infrared Spectroscopy is a well-established non-invasive optical imaging technique that uses near infrared light to measure regional changes in cerebral blood-oxygenation levels. Commonly used in clinical research, one prominent trend in recent years has been its increasing usage in the assessment and characterisation of task-related cortical function. When a patient is presented with a stimulus, we can estimate changes in local brain activity through a phenomenon known as haemodynamic response, in which cerebral metabolism increases in response to neuronal activity. This results in increased cerebral blood flow and so a detectable change in optical absorption, on which we can use the modified Beer-Lambert Law to estimate oxygenated and deoxygenated haemoglobin concentrations. The particular signal representing these changes is known as the haemodynamic response function.

However, single event-related analysis can be difficult in practice due to contamination by both systemic physiological signals and general signal quality issues that contribute to a low signal-to-noise ratio (SNR) in fNIRS measurements, such as the haemodynamics of the peripheral circulatory system in the scalp, low scalp connectivity due to sensor displacement with motion, or changes in other factors affecting CBF. These are numerous and difficult to simultaneously measure or quantify, including but not limited to cardiac output, blood pressure, inter-cranial pressure, respiration rate and so forth. 

\ul{1.2. Auto-Encoder Architecture}

Auto-Encoders are a form of unsupervised neural network architecture that encoder (compress) input data in a set of latent space features (the code) through a dimensionality reduction process, then reconstructs the input from those features. Auto-Encoders are considered to be "Self-Supervised", as they are trained by minimising their reconstruction error against their own unlabelled input, based on a loss function. Denoising Auto-Encoders are a specialised form of Auto-Encoders that intentionally corrupt the input data using noise before passing it through the model, then minimise the reconstruction error against the uncorrupted representation. The particular hidden layers used in both the encoder and decoder depend on the specific implementation of the Auto-Encoder.

\textbf{include if relevant to my paper, don't assume they'll read it somewhere else, but on the other hand if it isn't particularly relevant don't write about it. Write WHATEVER necessary to understand your research, but not unnecessary information.}

\textbf {Not completely sure if we need to discuss the pros and cons of this in too much detail? they can read up on it if they want to ----> }
Auto-Encoders have some limitations, in that they can be significantly more computationally expensive to train compared to other denoising methods, and the choices of layers ... On the other hand, as unsupervised methods, it is significantly easier to acquire large datasets for training. Auto-Encoders have been extensively used in Anomaly Detection and Denoising Imagery, including in practical medical imaging for enhancing the signal quality of MRI images by removing noise and artefacts. They have previously been used in fNIRS systems to remove motion artefacts [cit.].  

\ul{1.3. Current Preprocessing Methods} --> Requires a LOT more focus.

Preprocessing methods are able to enhance signal quality, and both increase classification accuracy and reduce the occurence of false positives by physiological signals that overlap with the frequencies typically exhibited by haemodynamic responce functions. Minimal preprocessing methods such as band-pass filtering are able to effectively remove some signals such as heart rate and ..., but require manual adjustment, and do not adequately cater to those with ... . Similar techniques such as wavelet filters offer increased performance but similar drawbacks (actually very different set of issues for those). Methods such as Independent Component Analysis 

General Linear Models benefit greatly from additional auxiliary measurements of systemic physiology, such as short-separation measurements or blood pressure measurements, accelerometers, respirometers etc... Not necessary if using this I guess...

\ul{\textbf{Method:}}
\vspace{-1mm}

\ul{Data Acquisition and Generation:}

The dataset used was taken from an open access dataset, containing task-free haemodynamic activity in 4-month old infants during sleep. There are 104 sets of raw measurements in the dataset, with no preprocessing having been performed on the data. Further details are described in the related paper [4].

As the ground-truth in our study, we use simulated clean HRF data, generated by the difference of two gamma functions. We obtain the parameters for this by fitting a linear regression model to the canonical HRF, and in order to prevent the model from overfitting, we vary the parameters for its generation slightly, as well as varying their magnitude. For each set of generated clean HRF data, we also included a blank reading, to allow the model to learn to de-noise samples without prior knowledge of activation period.

In terms of the resting state data used in training our models, we used three different sets of data: One set of completely simulated data, a set of real experimental resting state data, and a set of augmented experimental data. The simulated data was generated using an adapted method based on that of J. Gemignani et Al. [cit], by simulating each of the majorly contributing individual physiological signals in resting state fNIRS data according to data taken from literature, over random baseline white noise that was temporally correlated using a order 30 Autoregressive model. The physiological signals we considered were cardiac activity, respiration, Mayer waves, and very low frequency oscillations. Motion artefacts were generated using spikes based on the exponential distribution. We augmented the real dataset by generating similar synthetic data samples using an Auto-Regressive model of order 6 (appendix 1.3). The Auto-Regressive model was fit to random sub-sets of recordings from several different patients, and used to predict multiple "tapes" of measurements, which were then sampled and mixed with the real data at a ratio of 1:1.

The data was segregated into a 10 to 1 split, in which for each 10 samples used in training and validation, 1 was removed and stored for testing and evaluation. We additionally adopted a leave-one-out approach in order to be able to test the generalisation of the models, leaving out the measurements from a participant for testing.

\textbf{write all information potentially necessary for someone to replicate your experiment, e.g. if you couldn't follow through a partiuclar experiemtn due to a restriction e.g. comp power, mention that so someone else knows and doesn't have to find out the hard way themselves.}

\ul{Data Processing:}

To ensure the validity of our resting state data generation and experimental results, we discard all short-separation channels (which we took as any channel shorter than 10mm [cit. also pot. explain it]) which can only detect extra-cerebral tissue haemodynamics and so cannot contain  an HRF. Additionally, we truncated all recordings to the same length of 10 minutes. With the remaining data, we converted the raw data to optical density measurements, then applied Beer-Lambert's Law to obtain a set of haemoglobin measurements.

We used two separate representations of the data in training the model. The first is as a set of time series data, which we applied standardisation to on a per-sample basis. Secondly, we used a set of time frequency representations of the signals, obtained using a Discrete Wavelet Transform with a 4th order Symlet wavelet as the mother wavelet. We standardised the wavelet transformed data on a per-sample basis, standardising each frequency band independently, which we found to be an improvement over the approach of standardising data then converting it to the time frequency domain, and then additionally applied a set of frequency band weights that prioritised bands that coincided with known HRF frequencies [wavelet 5 -- cit.].

\ul{Models:}

In order to fairly assess the potential of the Auto-Encoder architecture, we considered a wide range of different architectures for both the encoder and decoder modules of our models, based on on particular relevant characteristics identified from literature. We tested 7 different models in total, and as such we will discuss the general structure of each model, but the particular implementation will not be described. It can instead be found in the accompanying code. When applicable, we used a LeakyReLU activation function and employed dropout layers with probability varying between 0.1 and 0.4.

The two basic architectures that we identified as being commonly used in Auto-Encoders, both in literature and practice, were the linear neural network for its simplicity and the convolutional neural network for its ability to capture spatial relationships and local patterns within the data. We employed a simple Linear model with 5 linear layers in both its encoder and decoder as a baseline with which to compare the other models against. For the convolution neural network approach, we considered two models with different structures. The first (basic) used 3 1D convolutional layers in the encoder and 4 in the decoder, with 64 channels in the feature space. The second (benchmark) follows the structure laid out in Yuanyuan et al's similar study, with 4 encoder layers and 5 decoder layers and 32 channels.

We also considered the combination of Auto-Encoders and Recurrent Neural Networks (RNNs), which have been commonly used in time series forecasting and denoising for their strong ability to capture temporal relationships. Particularly, we used 'Long Short Term Memory' (LSTM) networks. We considered two approaches based on this architecture, the first using an LSTM encoder but a Linear decoder, and the second using both an LSTM based encoder and decoder. For the first, we employed 2 LSTM layers and a linear fully connected layer in the encoder and 4 linear layers in the decoder, while in the second we used 4 LSTM layers in the encoder and 4 LSTM layers with a linear fully connected layer in the decoder.

The two final models we considered were firstly an ensemble Auto-Encoder, that used convolution and LSTM based Auto-Encoders to extract both temporal and spatial features and reconstruct two different representations of the signal, then used a stacking approach, using a linear layer to combine their predictions. We used the basic CNN and LSTM-Linear models for these respectively. Secondly, we consider a 2D convolutional model that uses an image of the wavelet transformed representation of the time series. We used 4 2D Convolutional layers in the encoder, and 6 in the decoder, and chose to have 32 intermediary channels.

In summary, we consider a Linear model, two 1D Convolutional models with different structures, an LSTM-encoder Linear-decoder model, an LSTM encoder-decoder model, a stacked-ensemble model with convolutional and LSTM models, and a 2D Convolutional model that uses an image of wavelet coefficients as input. 

\ul{Training Process:}

We trained each model over 100 epochs, with an initial learning rate of 1e-3 and a learning rate scheduler than halves it every 25 epochs. For each of the models, we trained three separate versions, one with 2,000 real samples, one with 10,000 synthetic samples, and the final with 2000 real samples and 2000 auto-regressive generated samples.
\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
Dataset & SNR & CNR & No. Samples & Sample Length\\
\hline
Synthetic Training &-53.00&0.0467&10000&234\\
Experimental Training &14.099&2.4714&2000&234\\
Augmented Training &10.514&2.0835&4000&234\\
Experimental Testing & 28.81 &0.2433 &1000&234\\
\end{tabular}
\caption{Initial Conditions}
\end{table}

\ul{Evaluatory Metrics:}

The measures that we used to evaluate signal quality before and after, and as such model performance, were:
 % put units in, or at least explain the metrics. Do not put formula, it isn't necessary
\begin{itemize}
    \item Signal-To-Noise Ratio (SNR) 
    \item Contrast-To-Noise Ratio (CNR)
\end{itemize}

Additionally, we will assess prediction and classification accuracy by comparing our predictions to the ground-truth data using:
\begin{itemize}
    \item Root Mean Squared Error (RMSE)
    \item Mean Absolute Error (MAE)
    \item Classification Accuracy (CA)
\end{itemize}

[For a more detail explanation of these metrics, see appendix 1.9]

\ul{Additional Toolkit Features:}
...

\underline{\textbf{Results:}}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Model & SNR & CNR & MAE & RMSE & Pos. CA & Neg. CA \\
\hline
Basic Linear & 28.81 & 13.45 & 0.5399& 0.6949 & 0.996 & 0.126 \\
Basic CNN &24.94&0.610&0.6377&0.8339&1.0&0.018\\
Bench. CNN &28.85&0.059&0.5445&0.7516&1.0&0.058\\
Simple LSTM &37.72&2.474&0.4576&0.5609&0.996&0.286\\
Deep LSTM &62.93&43.75&0.3273&0.4211&0.99&0.488\\
Stacked AE &57.18&20.67&0.3587&0.4630&0.96&0.46\\
\end{tabular}
\caption{Training Using Synthetic Data}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Model & SNR & CNR & MAE & RMSE & Pos. CA & Neg. CA \\
\hline
Basic Linear &60.65&3.052&0.1493&0.1947&0.928&0.928\\
Basic CNN &51.28&2.121&0.2097&0.2867&0.9744&0.718\\
Bench. CNN &54.30&0.097&0.1809&0.2460&0.97&0.784\\
Simple LSTM &54.14&7.103&0.1959&0.2459&0.95&0.754\\
Deep LSTM &75.52&12.71&0.1402&0.1833&0.932&0.874\\
Stacked AE &66.73&4.63&0.1407&0.1828&0.934&0.926\\
\end{tabular}
\caption{Training Using Real Experimental Data}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Model & SNR & CNR & MAE & RMSE & Pos. CA & Neg. CA \\
\hline
Basic Linear &64.46&3.552&0.5399&0.6949&0.936&0.918\\
Basic CNN &49.53&3.634&0.2056&0.2904&0.974&0.718\\
Bench. CNN &57.69&2.605&0.1620&0.2290&0.98&0.644\\
Simple LSTM &55.52&9.56&0.1853&0.2351&0.96&0.792\\
Deep LSTM &78.44&11.29&0.1249&0.1623&0.954&0.864\\
Stacked AE &67.47&5.231&0.1323&0.1711&0.934&0.918\\
\end{tabular}
\caption{Training Using Augmented Experimental Data}
\end{table}
\vspace{10cm}

\underline{Discussion:}

\underline{Citations:}

[1] 

[4] Open access dataset of task-free haemodynamic activity in 4-month-old infants during sleep using fNIRS. B. Blanco et al. etc.etc. do a proper citation later

[6] Regulation of Cerebral blood flow in humans: physiology and clinical implications of auto-regulation.

\underline{NOTES}
The properties of physiological noise studied as well as denoising/ classification methods have been focused on healthy, neurotypical individuals. Diseases affecting functional connectivity can affect baseline resting state, as shown in studies such as {Functional connectivity as revealed by independent component analysis of resting-state fNIRS measurements, H. Zhang et al.}, or respiratory conditions, cardiovascular conditions, neurological conditions {brain damage, neuron connectivity damage, strokes} etc. Also, cerbrovascular diseases.

\underline{Appendix}

[1.3] We chose an order of 6 as it was the last statistically significant value according to the results of a partial Auto-Correlation Function (pACF) test on the experimental data, with a significance threshold of 0.2 [cit.]. The pACF measures the correlation between a value and its k'th time lagged term, after adjusting for the intermediary lagged terms, and we want to take the largest possible order such that the model includes all relevant lagged terms that have a direct effect on the model's prediction of the subsequent value.


[1.6] Although it was possible to use more samples in training the models, our reasoning was in constraining the size of the training set was that it more closely simulates the conditions of a real fNIRS experiment with more limited readings. In addition, due to limited computing power, using very large datasets resulted in excessively long training times.


\end{document}